# B-Recon

<div align="center">

![B-Recon Banner](assets/banner.png)

**AI-Powered Automated Reconnaissance Toolkit**

A modern recon engine combined with an AI assistant that explains findings, supports natural-language commands, and provides a clean web-based UI.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

</div>

---

## ğŸš€ Overview

B-Recon is a hybrid reconnaissance toolkit that combines a classic recon pipeline with an AI assistant powered by local LLMs. Originally built as a learning project, it has evolved into a practical, well-structured tool designed for security professionals and penetration testers.

### What You Get

- **Automated Recon Pipeline** â€“ Subdomain enumeration, port scanning, technology detection, and more
- **AI Assistant** â€“ Natural-language commands that understand intent and explain findings
- **Web Chat Interface** â€“ Clean, modern UI for interactive scanning and reporting
- **Professional Reports** â€“ Markdown, HTML, and human-readable summaries

---

## âœ¨ Features

### ğŸ” Reconnaissance Engine

- âœ… Subdomain enumeration (wordlist-based)
- âœ… Deep subdomain scanning
- âœ… Certificate Transparency (CT) log collection
- âœ… Technology fingerprinting
- âœ… Email scraping
- âœ… Port scanning with optional service banners
- âœ… Screenshots (optional headless browser)
- âœ… Multiple report formats (Markdown, HTML, summary)

### ğŸ¤– AI Assistant

- âœ… Natural-language command understanding
- âœ… Intent detection (scan/explain/general knowledge)
- âœ… Automatic output parsing and analysis
- âœ… Clear, analyst-friendly explanations
- âœ… Powered by local LLM (Ollama) â€“ no cloud dependencies

### ğŸ’¬ Web Interface

- âœ… Real-time chat with live progress updates
- âœ… Download generated reports directly
- âœ… Typing indicators and auto-scroll
- âœ… Responsive design

---

## ğŸ“‹ Requirements

### System Requirements

- **OS:** Linux (Kali, Debian, Ubuntu tested)
- **Python:** 3.11 or higher
- **RAM:** 2GB+ recommended

### External Dependencies

Required:
- `nmap` â€“ Port scanning
- `ffuf` â€“ Subdomain enumeration
- `curl`, `wget` â€“ HTTP utilities

Optional:
- `Playwright` + headless browser â€“ For screenshots
- `Ollama` â€“ For local LLM inference

### Python Dependencies

All Python packages are listed in `requirements.txt`

---

## ğŸ› ï¸ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/B-Recon.git
cd B-Recon
```

### 2. Create Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

On Windows:
```cmd
python3 -m venv venv
venv\Scripts\activate
```

### 3. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### 4. Install System Tools (Linux/Debian/Kali)

```bash
sudo apt update
sudo apt install -y nmap ffuf curl wget
```

On macOS (using Homebrew):
```bash
brew install nmap ffuf curl wget
```

### 5. Set Up Ollama (for AI Assistant)

Download and install [Ollama](https://ollama.ai/), then start the server:

```bash
ollama serve
```

In another terminal, download a lightweight model:

```bash
ollama pull llama2:7b
```

Or use `llama3.2:1b` for faster inference on limited hardware.

---

## ğŸ–¥ï¸ Usage

### Option 1: Classic CLI

Run reconnaissance scans from the command line:

```bash
# Full reconnaissance
python autorecon/cli.py full tesla.com

# Individual scans
python autorecon/cli.py subdomains tesla.com
python autorecon/cli.py ports tesla.com
python autorecon/cli.py screenshots tesla.com
python autorecon/cli.py emails tesla.com
```

Results are stored in:
```
autorecon-results/<domain>/
```

### Option 2: Web Chat Interface (Recommended)

Start the FastAPI server:

```bash
uvicorn api.ask_ai:app --host 0.0.0.0 --port 8000 --reload
```

Open your browser and navigate to:

```
http://127.0.0.1:8000/chat/
```

#### Example Commands

```
"Do a full recon on tesla.com"
"Scan ports of paypal.com"
"Explain the last scan"
"What does an open 3389 port mean?"
"Find subdomains for example.com"
"Screenshot all discovered subdomains"
```

The AI assistant will:
- Parse your command
- Execute the appropriate scan
- Display real-time progress
- Explain results in plain English
- Provide download links for reports

---

## ğŸ“ Project Structure

```
B-Recon/
â”œâ”€â”€ ai/
â”‚   â””â”€â”€ ai_agent.py              # LLM logic, intent detection, explanations
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ ask_ai.py                # FastAPI backend (chat, progress, downloads)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ autorecon/
â”‚   â”œâ”€â”€ cli.py                   # Classic recon pipeline
â”‚   â”œâ”€â”€ subdomains_big.txt       # Large wordlist
â”‚   â”œâ”€â”€ subdomains_small.txt     # Quick wordlist
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ recon_api.py             # Orchestration layer
â”‚   â””â”€â”€ screenshot_service.py    # Headless browser logic
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_all.sh               # Development helper scripts
â”‚
â”œâ”€â”€ web/
â”‚   â””â”€â”€ index.html               # Web chat UI (HTML + JS)
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ logo.png                 # Project logo
â”‚   â””â”€â”€ banner.png               # README banner
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml               # CI/CD pipeline
â”‚
â”œâ”€â”€ Dockerfile                   # Docker configuration
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ MANIFEST.in
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ setup.py                     # Package configuration
```

---

## ğŸš€ Quick Start

### Minimal Setup (CLI Only)

```bash
# Clone and setup
git clone https://github.com/your-username/B-Recon.git
cd B-Recon
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
sudo apt install -y nmap ffuf curl wget

# Run a scan
python autorecon/cli.py full example.com
```

### Full Setup (Web UI + AI)

```bash
# Complete installation (from steps above)
# Then start both services:

# Terminal 1: Start Ollama
ollama serve

# Terminal 2: Start API server
source venv/bin/activate
uvicorn api.ask_ai:app --host 0.0.0.0 --port 8000 --reload

# Terminal 3: Open in browser
# Navigate to http://127.0.0.1:8000/chat/
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Web Chat Interface                     â”‚
â”‚                    (index.html)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    HTTP/WebSocket
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Backend (ask_ai.py)                â”‚
â”‚          Chat routes, progress tracking, downloads      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  AI Agent  â”‚  â”‚ Recon API â”‚  â”‚ Screenshot  â”‚
    â”‚  (Ollama)  â”‚  â”‚  (Backend)â”‚  â”‚  Service    â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚            â”‚              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚               â”‚               â”‚
    â”Œâ”€â”€â–¼â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”      â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
    â”‚nmap â”‚      â”‚ffuf    â”‚      â”‚curl   â”‚
    â””â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”˜
  (Port scan)  (Subdomains)  (HTTP requests)
```

---

## âš™ï¸ Configuration

### Changing LLM Model

Edit `ai/ai_agent.py` and modify the model parameter:

```python
response = ollama.generate(model="llama3.2:1b", prompt=prompt)
```

Available models: `llama2:7b`, `mistral:7b`, `neural-chat:7b`

### Adjusting Scan Depth

Modify timeout and wordlist settings in `autorecon/cli.py`:

```python
WORDLIST = "subdomains_small.txt"  # Quick scan
WORDLIST = "subdomains_big.txt"    # Deep scan
```

### Port Scan Range

Edit the nmap command in `backend/recon_api.py`:

```python
nmap -p 1-65535 target.com  # Full range
nmap -p 1-10000 target.com  # Quick range
```

---

## ğŸ“Š Example Output

### CLI Report
```
[*] Scanning tesla.com
[+] Found 247 subdomains
[+] Open ports: 80, 443, 22
[+] Technologies: nginx, OpenSSL, Cloudflare
[+] Report saved: autorecon-results/tesla.com/report.md
```

### Web UI
- Real-time progress updates
- Downloadable reports (Markdown, HTML)
- AI-generated summaries and explanations

---

## ğŸ³ Docker Support

Build and run with Docker:

```bash
docker build -t b-recon .
docker run -p 8000:8000 -it b-recon
```

Visit `http://localhost:8000/chat/`

---

## ğŸ“š Documentation

- **CLI Usage** â€“ See `autorecon/cli.py` for detailed command options
- **API Routes** â€“ FastAPI auto-docs at `http://127.0.0.1:8000/docs`
- **AI Agent** â€“ Custom intent detection logic in `ai/ai_agent.py`

---

## âš ï¸ Legal Disclaimer

**This tool is for authorized security testing ONLY.**

- Only use B-Recon on domains/systems you own or have explicit written permission to test
- Unauthorized access to computer networks is illegal
- Respect laws and regulations in your jurisdiction
- The authors are not responsible for misuse

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Powered by [Ollama](https://ollama.ai/) for local LLM inference
- Built with [FastAPI](https://fastapi.tiangolo.com/) and [Playwright](https://playwright.dev/)

---

<div align="center">

**Built with â¤ï¸ and curiosity**

[â¬† Back to top](#b-recon)

</div>
